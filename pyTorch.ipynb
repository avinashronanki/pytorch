{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyTorch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOROIjWI/xpx/u7NOGaqFQs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avinashronanki/pytorch/blob/master/pyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_SRKjqyvZCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "x = torch.rand(3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHK-LzxxyMQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available().  # to check if gpu is connected or not "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1l7mMB8y5Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty = torch.empty(3) # un intialized memory /data \n",
        "print(empty)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYULsopSzUqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero = torch.zeros(3)\n",
        "print(zero)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UifAChtezhsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty + one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txLjGDy-zy1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one = torch.ones(3)\n",
        "print(one)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgUr2ER10H1g",
        "colab_type": "text"
      },
      "source": [
        "create 2d 3d and 4d tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ldNM2V0M44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twod = torch.rand(2,2)\n",
        "threed = torch.rand(2,2,2)\n",
        "fourd = torch.rand(2,2,2,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEMzRphO1QJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c  = torch.ones(2,2, dtype =torch.float) # mention date type "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzCiH6in1IYw",
        "colab_type": "text"
      },
      "source": [
        "list "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQHd6D4t05Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = torch.ones([1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLADFK2E0p8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfajHdpw2E_m",
        "colab_type": "text"
      },
      "source": [
        "Adding two tensors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCMa8gb12Qu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ef55555-d942-4b97-ce8c-83244923ab92"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "z= x+y   \n",
        "print(z)\n",
        "\n",
        "z = torch.add(x,y) # add function \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8325, 1.3713],\n",
            "        [0.8632, 0.8652]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj7T32b33Jg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84d31f96-9f43-4e19-dca0-52814694305e"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6337, 0.7274],\n",
            "        [0.4152, 0.3477]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du3s5wfT28W4",
        "colab_type": "text"
      },
      "source": [
        "modify the variable with addition "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPD0_DAU27Tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e924d51-77ac-4aec-8ffa-1afec476bd45"
      },
      "source": [
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8325, 1.3713],\n",
            "        [0.8632, 0.8652]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Poa00jB3ZpB",
        "colab_type": "text"
      },
      "source": [
        "substraction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CYTyCXn3cpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "z= x-y   \n",
        "print(z)\n",
        "\n",
        "z = torch.sub(x,y) # substraction function "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXeWLce-3jAf",
        "colab_type": "text"
      },
      "source": [
        "divison "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ABj2Y23lyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "z= x/ y   \n",
        "print(z)\n",
        "\n",
        "z = torch.div(x,y) # division  function "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be7UguIL6BKU",
        "colab_type": "text"
      },
      "source": [
        "Slice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFcx2xtJ4Aj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.rand(5,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ-C0xxF4YOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "45e764d0-c169-41fd-cf70-c0854f957b82"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9725, 0.8286, 0.1985, 0.6716],\n",
            "        [0.5158, 0.3561, 0.6893, 0.1104],\n",
            "        [0.8168, 0.3879, 0.8921, 0.6888],\n",
            "        [0.7019, 0.3297, 0.7578, 0.1883],\n",
            "        [0.5933, 0.2272, 0.2099, 0.8052]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQfUoj_4NyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(a[1:3,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9YSE0nT4z6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(a[[2,4],:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPhhhiX85UpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fe75fb7-e9a8-4dd4-b400-ea008466df98"
      },
      "source": [
        "a[1,1] # taking a specific postion "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3561)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXmU8GKg5k22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "464cb33c-6295-4b8d-a68b-ea06e5c67138"
      },
      "source": [
        "a[1,1].item()   # if you need the value of the tensor "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3561347723007202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXRsSn_b6gE9",
        "colab_type": "text"
      },
      "source": [
        "REshape "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OCYon8_6jKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "885b861a-c824-402b-a7cf-dba27b150e76"
      },
      "source": [
        "r = torch.rand(6,6)\n",
        "print (r)\n",
        "y = r.view(36) # in a single list \n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9520, 0.2428, 0.4987, 0.7993, 0.8776, 0.7078],\n",
            "        [0.9136, 0.2007, 0.8112, 0.7529, 0.3412, 0.7893],\n",
            "        [0.9817, 0.1569, 0.0114, 0.0199, 0.5911, 0.3896],\n",
            "        [0.7242, 0.4373, 0.9833, 0.1772, 0.8281, 0.1766],\n",
            "        [0.5861, 0.9514, 0.2313, 0.0517, 0.6457, 0.7085],\n",
            "        [0.0889, 0.1592, 0.9855, 0.2104, 0.8430, 0.4124]])\n",
            "tensor([0.9520, 0.2428, 0.4987, 0.7993, 0.8776, 0.7078, 0.9136, 0.2007, 0.8112,\n",
            "        0.7529, 0.3412, 0.7893, 0.9817, 0.1569, 0.0114, 0.0199, 0.5911, 0.3896,\n",
            "        0.7242, 0.4373, 0.9833, 0.1772, 0.8281, 0.1766, 0.5861, 0.9514, 0.2313,\n",
            "        0.0517, 0.6457, 0.7085, 0.0889, 0.1592, 0.9855, 0.2104, 0.8430, 0.4124])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZdfhaXj6-Rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert into 8 column metric \n",
        "\n",
        "y = r.view(-1, 9)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51dtxeye7bne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = r.view(2, -1)\n",
        "print(z.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwnmqSNI8Ijn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "524zXeKg8pHS",
        "colab_type": "text"
      },
      "source": [
        "numpy array "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgqvMpXi8JGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ee2b257-4e51-422a-ebac-6a6a4e9f957e"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4WzOiuo9dbD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a91f2d4a-5d18-44fb-e256-8a120d005faf"
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHylJra497Wz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3fcb799-4557-4f38-c29d-4de02c7961b8"
      },
      "source": [
        "# numpy to tensor \n",
        "\n",
        "n = np.ones(5)\n",
        "print(n)\n",
        "t = torch.from_numpy(n)\n",
        "print(t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgTGYd2G-acI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "950b665f-5cff-48ff-87ee-0700b5ad27ab"
      },
      "source": [
        "n += 1\n",
        "print(n)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ysMNFf-xS4",
        "colab_type": "text"
      },
      "source": [
        "cuda "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBapYanw-1MI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d06b88a5-d8b7-4634-8722-4e732c0513cf"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  x = torch.ones(5, device= device)\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device) # converting into cuda \n",
        "  z= x+y \n",
        "\n",
        "  print(z)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9mZyrg6ABbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# moving it back to cpu version \n",
        "z= z.to(\"cpu\") # important \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfO8vvgjAswn",
        "colab_type": "text"
      },
      "source": [
        "Gradients calculation with Autogred "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQR74YAyA2IX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f53b37dc-2716-4300-8fac-097e811d1b7f"
      },
      "source": [
        "g = torch.ones(5, requires_grad=True)\n",
        "print(g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdWp7riZBOIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ba857643-9cd7-4859-a0ec-d772f5656d62"
      },
      "source": [
        "x = torch.rand(3,3, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x+2\n",
        "print (y) #  grad_fn=<AddBackward0> "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4301, 0.7209, 0.7149],\n",
            "        [0.2627, 0.6174, 0.3840],\n",
            "        [0.8414, 0.7427, 0.7175]], requires_grad=True)\n",
            "tensor([[2.4301, 2.7209, 2.7149],\n",
            "        [2.2627, 2.6174, 2.3840],\n",
            "        [2.8414, 2.7427, 2.7175]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPNuJHeCQsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "53043ce8-b6ed-4bd3-b6db-fbd1c74c883a"
      },
      "source": [
        "z = y*y*2\n",
        "\n",
        "print (z) #grad_fn=<MulBackward0>)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[11.8104, 14.8063, 14.7417],\n",
            "        [10.2396, 13.7019, 11.3670],\n",
            "        [16.1467, 15.0444, 14.7700]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGA5gQ_rCe2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05711fea-2719-44cc-fe9f-81d804ba4040"
      },
      "source": [
        "z = z.mean()\n",
        "print(z) # grad_fn=<MeanBackward0>)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(13.6253, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ax2y6BYCt2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "47e5017e-a82c-4342-f4d2-7c9115a34e94"
      },
      "source": [
        "# backward pass \n",
        "z.backward() # dz/dx\n",
        "print (x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0800, 1.2093, 1.2066],\n",
            "        [1.0056, 1.1633, 1.0596],\n",
            "        [1.2628, 1.2190, 1.2078]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6ESW2WtEEyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with out disturbing the gradents perfroming some operation on x \n",
        "x = torch.rand(3, requires_grad=True)\n",
        "print(x)\n",
        "x.requires_grad(False)\n",
        "x.detach()\n",
        "with torch.no_grad()\n",
        "\n",
        "y = X+2 \n",
        "print (y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vunTeplWGwkc",
        "colab_type": "text"
      },
      "source": [
        "Neural network with weights "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzR04wB0HBq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "11463a68-58e9-4b7a-97f7-cb0f291a666b"
      },
      "source": [
        "import torch \n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "print(weights)\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()\n",
        "  print(model_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor(12., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDtic0WxJSdT",
        "colab_type": "text"
      },
      "source": [
        "optimizer SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL4IOj9OJX69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "optimizer = torch.optim.SGD(weights, lr= 0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYNmqnJxKjp4",
        "colab_type": "text"
      },
      "source": [
        "Backpropagation \n",
        "1. forward pass (loss)\n",
        "2.local gradients \n",
        "3.backword propagation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoirCyGwKn0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1b3191ab-c277-4843-a358-f27668337255"
      },
      "source": [
        "# chain rule \n",
        "# computational graph \n",
        "\n",
        "#linear regression \n",
        "\n",
        "\n",
        "import torch \n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w= torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "#forword pass and compute loss\n",
        "\n",
        "y_hat = w * x\n",
        "loss =(y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "#backword pass \n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCIW9uwLTMKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edU1m15vUH4x",
        "colab_type": "text"
      },
      "source": [
        "Gradient Descent With Autograd and Backpropagation \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7aL9en3UUxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction : pytoch model \n",
        "GD : Auto grad \n",
        "Loss Computation : loss function \n",
        "parameter : optimizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsNZ4AQvbwH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#linear Regression \n",
        "\n",
        "X = np.array([1,2,3,4], dtype=np.float32)\n",
        "Y = np.array([2,4,6,8], dtype=np.float32)\n",
        "w=0.0\n",
        "\n",
        "\n",
        "#model prediction \n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "#loss =MSE\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted - y)**2).mean()\n",
        "\n",
        "\n",
        "#gardient\n",
        "#MSE = 1/N * (w*x -y) **2\n",
        "#d/dw =1/N 2x (w*x -y)\n",
        "def gradient( x, y, y_predicted):\n",
        "  return np.dot(2*x, y_predicted -y).mean()\n",
        "\n",
        "print(\"Prediction before training: f(5) = {forward(5):.3f}\")\n",
        "\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  #loss\n",
        "  l = loss( Y, y_pred)\n",
        "\n",
        "\n",
        "  #gradients\n",
        "  dw = gradient( X, Y, y_pred)\n",
        "\n",
        "\n",
        " #update weights\n",
        "  w -=learning_rate * dw\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss {l:.8f}')\n",
        "\n",
        "print(f\"Prediction after training: f(5) = {forward(5):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4ILPkXucmTz",
        "colab_type": "text"
      },
      "source": [
        "Liner regression with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdBqMjW_cs0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "#needs an input size and output size as features .. need to be a 2D array .. no of rows is the no of samples so change the shape of X & Y \n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32) \n",
        "\n",
        "\n",
        "n_samples, n_features =X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "#remove the weights since the function nn.linear() contains the weights inbuilt linear regression function by pytorch\n",
        "#model prediction \n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# foward == model \n",
        "\n",
        "# weigths become models.paramters  // used by DeClare\n",
        "#linear model with random weigths will be created\n",
        "\n",
        "\n",
        "#creating a custom model ( where many layers can be added for fine tuning)\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "      super(LinearRegression, self).__init__()   # super constructer\n",
        "      #define layers here \n",
        "      self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "     return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(\"Prediction before training: f(5) = {model(X_test).item():.3f}\")\n",
        "\n",
        "# remove the loss function and add the built in function MSELoss()\n",
        "\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "\n",
        "# acts as a back propogation\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  #loss\n",
        "  l = loss( Y, y_pred)\n",
        "\n",
        "\n",
        "  #gradients = backward pass\n",
        "  l.backward() #loss with respect to w --> dl/dw\n",
        "  \n",
        "  # dw = gradient( X, Y, y_pred)\n",
        "\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "  if epoch % 10 == 0:\n",
        "    # wanrt to print so unpack them \n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss {l:.8f}')\n",
        "\n",
        "print(f\"Prediction after training: f(5) = {model(X_test).item():.3f}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-dPBsNvTxi1",
        "colab_type": "text"
      },
      "source": [
        "# 1) Design model( input, output size, forward pass)     \n",
        "# 2) Construct loss and optimizer.       l=((y_predicted - y)**2).mean()\n",
        "# 3) Training loop\n",
        "#     - Forward pass: compute prediction.   w * x        :Loss\n",
        "#     - Backward pass: gardient     l.backward\n",
        "#     - Update the weigths ( keep going in a loop untill the loss is minimized).    w - =lr *w.grad --> Optimizer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PetXkLZng7OO",
        "colab_type": "text"
      },
      "source": [
        "using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hqNT_ZsT-Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import numpy as np\n",
        "from sklearn import datasets \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# prepare data \n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples= 100, n_features=1, noise=20, random_state= 1)\n",
        "\n",
        "#print(X_numpy,y_numpy)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "\n",
        "y= y.view(-1 ,1 )\n",
        "\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# model\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "#loss function \n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "#training loop\n",
        "\n",
        "num_epochs = 500 \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "  #loss\n",
        "  loss = criterion( y_pred, y)\n",
        "\n",
        "  #gradients = backward pass\n",
        "  loss.backward() #loss with respect to w --> dl/dw\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch {epoch+1}: loss =  {loss.item():.8f}')\n",
        "\n",
        " #plot \n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy,y_numpy,\"ro\")\n",
        "\n",
        "plt.plot(X_numpy, predicted, \"b\")\n",
        "\n",
        "plt.show()\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_scJe7rbiJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLFfz6vUgtF0",
        "colab_type": "text"
      },
      "source": [
        "#Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNPCxpI3gzKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import numpy as np\n",
        "from sklearn import datasets \n",
        "from sklearn.preprocessing import StandardScaler # \n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk8qLYWNheHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ee9d75f6-ef82-4164-dc81-fc4a3da658de"
      },
      "source": [
        "bc = datasets.load_breast_cancer()\n",
        "\n",
        "X,y = bc.data, bc.target\n",
        "\n",
        "n_samples,n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "#scale\n",
        "\n",
        "sc = StandardScaler() #recommend to do \n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "\n",
        "#reshape \n",
        "\n",
        "y_train = y_train.view(-1,1)\n",
        "y_test = y_test.view(-1,1)\n",
        "\n",
        "#model \n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self,n_inputs_features):\n",
        "    super(LogisticRegression,self).__init__()\n",
        "    self.linear = nn.Linear(n_inputs_features, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted \n",
        "\n",
        "model = LogisticRegression(n_features)    \n",
        "\n",
        "\n",
        "\n",
        "# loss and optimizer \n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss() # binary cross entopy \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "# training loop\n",
        "\n",
        "num_epochs = 30000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #prediction = forward pass\n",
        "  y_predicted = model(X_train)\n",
        "  #loss\n",
        "  loss = criterion( y_predicted, y_train)\n",
        "\n",
        "  #gradients = backward pass\n",
        "  loss.backward() #loss with respect to w --> dl/dw\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10000 == 0:\n",
        "    print(f'epoch {epoch+1}: loss =  {loss.item():.8f}')\n",
        "\n",
        "#evaluation \n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()  \n",
        "  acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])  \n",
        "  print (f\"accuray = {acc:4f}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10000: loss =  0.04072985\n",
            "epoch 20000: loss =  0.03326616\n",
            "epoch 30000: loss =  0.02980602\n",
            "accuray = 0.956140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh3CF87m0ba-",
        "colab_type": "text"
      },
      "source": [
        "#dataset and data loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-_j1rw20l3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}